<!DOCTYPE html>




<html
 dir="ltr"
 lang="en"
 class="has-navbar-fixed-top">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content=#ffffff>
    <link rel="stylesheet" href="/assets/css/app.css">
    <link rel="shortcut icon" type="image/png"
           href="/favicon.png" 
    />
    <script defer src="https://unpkg.com/alpinejs@3.9.0/dist/cdn.min.js"></script>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">
    
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma-social@1/bin/bulma-social.min.css">
    
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Constrained and Multirate Training of Neural Networks | Montreal MLOpt</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Constrained and Multirate Training of Neural Networks" />
<meta name="author" content="Tiffany Vlaar" />
<meta property="og:locale" content="en" />
<meta name="description" content="I will describe algorithms for regularizing and training deep neural networks. Soft constraints, which add a penalty term to the loss, are typically used as a form of explicit regularization for neural network training. In this talk I describe a method for efficiently incorporating constraints into a stochastic gradient Langevin framework for the training of deep neural networks. In contrast to soft constraints, our constraints offer direct control of the parameter space, which allows us to study their effect on generalization. In the second part of the talk, I will focus on the role played by individual layers and substructures of neural networks. In particular, I will show that by choosing appropriate partitionings of the network parameters into fast and slow parts, a multirate approach can be used to train deep neural networks for transfer learning applications in vision and natural language processing in half the time, without reducing the generalization performance of the model." />
<meta property="og:description" content="I will describe algorithms for regularizing and training deep neural networks. Soft constraints, which add a penalty term to the loss, are typically used as a form of explicit regularization for neural network training. In this talk I describe a method for efficiently incorporating constraints into a stochastic gradient Langevin framework for the training of deep neural networks. In contrast to soft constraints, our constraints offer direct control of the parameter space, which allows us to study their effect on generalization. In the second part of the talk, I will focus on the role played by individual layers and substructures of neural networks. In particular, I will show that by choosing appropriate partitionings of the network parameters into fast and slow parts, a multirate approach can be used to train deep neural networks for transfer learning applications in vision and natural language processing in half the time, without reducing the generalization performance of the model." />
<link rel="canonical" href="http://localhost:4000/talks_entries/2023/2023_07_12_Vlaar.html" />
<meta property="og:url" content="http://localhost:4000/talks_entries/2023/2023_07_12_Vlaar.html" />
<meta property="og:site_name" content="Montreal MLOpt" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-07-12T13:30:00-04:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Constrained and Multirate Training of Neural Networks" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Tiffany Vlaar"},"dateModified":"2023-07-12T13:30:00-04:00","datePublished":"2023-07-12T13:30:00-04:00","description":"I will describe algorithms for regularizing and training deep neural networks. Soft constraints, which add a penalty term to the loss, are typically used as a form of explicit regularization for neural network training. In this talk I describe a method for efficiently incorporating constraints into a stochastic gradient Langevin framework for the training of deep neural networks. In contrast to soft constraints, our constraints offer direct control of the parameter space, which allows us to study their effect on generalization. In the second part of the talk, I will focus on the role played by individual layers and substructures of neural networks. In particular, I will show that by choosing appropriate partitionings of the network parameters into fast and slow parts, a multirate approach can be used to train deep neural networks for transfer learning applications in vision and natural language processing in half the time, without reducing the generalization performance of the model.","headline":"Constrained and Multirate Training of Neural Networks","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/talks_entries/2023/2023_07_12_Vlaar.html"},"url":"http://localhost:4000/talks_entries/2023/2023_07_12_Vlaar.html"}</script>
<!-- End Jekyll SEO tag -->

    <!-- head scripts --></head>

  <body>
    <nav class="navbar is-primary  is-fixed-top " x-data="{ openNav: false }">
    <div class="container">
        <div class="navbar-brand">
            <a href="/" class="navbar-item">
                Montreal MLOpt
            </a>
            <a role="button" class="navbar-burger burger" aria-label="menu" aria-expanded="false" data-target="navMenu" :class="{ 'is-active': openNav }" x-on:click="openNav = !openNav">
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>
        <div class="navbar-menu" id="navMenu" :class="{ 'is-active': openNav }">
            <div class="navbar-start">
                <a href="/" class="navbar-item ">Home</a>
                
                
                    
                    <a href="/talks" class="navbar-item ">Talks schedule</a>
                    
                
                    
                    <div class="navbar-item has-dropdown is-hoverable ">
                        <a href="/organizers" class="navbar-link ">Organizers</a>
                        <div class="navbar-dropdown">
                            
                            <a href="/organizers" class="navbar-item ">All</a>
                            
                            <a href="/organizers#current" class="navbar-item ">Current</a>
                            
                            <a href="/organizers#alumnis" class="navbar-item ">Past organizers</a>
                            
                        </div>
                    </div>
                    
                
                    
                    <a href="/archive/index.html" class="navbar-item ">Archive</a>
                    
                
                
            </div>

            <div class="navbar-end">
                
            </div>

        </div>
    </div>
</nav>

    
        <section class="hero  is-small  is-bold is-primary" >
    <div class="hero-body ">
        <div class="container">
            <h1 class="title is-2">Constrained and Multirate Training of Neural Networks</h1>
            <p class="subtitle is-3"></p>
            
        </div>
    </div>
</section>
    
    


    <section class="section">
        <div class="container">
            <div class="columns is-multiline">
                
                <div class="column is-12">
                    
                    

                    
                    
                    
<div class="content">
    <h2> Speaker: Tiffany Vlaar </h2>

<div> <b>Where:</b> Auditorium 1.</div> 
<div> <b>When:</b> July 12, 2023 at 13:30.</div>








<h2> Abstract </h2>

<div> <p>I will describe algorithms for regularizing and training deep neural networks. Soft constraints, which add a penalty term to the loss, are typically used as a form of explicit regularization for neural network training. In this talk I describe a method for efficiently incorporating constraints into a stochastic gradient Langevin framework for the training of deep neural networks. In contrast to soft constraints, our constraints offer direct control of the parameter space, which allows us to study their effect on generalization. In the second part of the talk, I will focus on the role played by individual layers and substructures of neural networks. In particular, I will show that by choosing appropriate partitionings of the network parameters into fast and slow parts, a multirate approach can be used to train deep neural networks for transfer learning applications in vision and natural language processing in half the time, without reducing the generalization performance of the model.</p>
</div>


<div class="tags">
    
</div>


<p><strong>Share</strong></p>
<div class="buttons ">
    <a class="button is-medium is-facebook"
       onclick="window.open('https://www.facebook.com/share.php?u=http://localhost:4000/talks_entries/2023/2023_07_12_Vlaar.html');">
        <span class="icon"><i class="fab fa-facebook fa-lg"></i></span>
    </a>
    <a class="button is-medium is-twitter"
       onclick="window.open('https://twitter.com/intent/tweet?text=http://localhost:4000/talks_entries/2023/2023_07_12_Vlaar.html');">
        <span class="icon"><i class="fab fa-twitter fa-lg"></i></span>
    </a>
    <a class="button is-medium is-linkedin"
       onclick="window.open('https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/talks_entries/2023/2023_07_12_Vlaar.html&title=Constrained+and+Multirate+Training+of+Neural+Networks&summary=&source=');">
        <span class="icon"><i class="fab fa-linkedin fa-lg"></i></span>
    </a>
    <a class="button is-medium is-reddit"
       onclick="window.open('https://reddit.com/submit?url=http://localhost:4000/talks_entries/2023/2023_07_12_Vlaar.html');">
        <span class="icon"><i class="fab fa-reddit fa-lg"></i></span>
    </a>
</div>



</div>
                </div>
                
            </div>
        </div>
    </section>
    
        <footer class="footer">
    <div class="container">
        
        

        <div class="content is-small has-text-centered">
            <p class="">Theme built by <a href="https://www.csrhymes.com">C.S. Rhymes</a></p>
        </div>
    </div>
</footer>

    
    <script src="/assets/js/app.js" type="text/javascript"></script><!-- footer scripts --></body>
</html>
